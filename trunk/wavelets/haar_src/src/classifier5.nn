3
33 15 1 

linear
sigmoid
sigmoid

0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1
0		1

-0.822247
-1.01812
-12.1893
-13.2133
9.82038
12.6035
3.72435
-5.52892
-5.1703
5.71549
8.20909
24.9477
-2.62105
2.51429
-12.7111
15.1542
5.06614
13.8964
-7.55332
-2.95645
-8.00652
-3.59415
-9.62188
-4.84687
7.6589
-12.9891
-3.24917
-2.99096
13.1957
-2.46141
1.31562
1.31668
-6.40588
6.24767
-3.17186
0.971435
0.0330239
-0.633606
-0.115432
0.935389
1.15491
1.10806
-0.38076
1.28539
0.322995
-0.161912
0.212126
-0.864424
-0.56406
-0.22348
0.886986
0.671784
-1.29829
-0.280266
-0.196457
-0.347227
0.129927
0.710034
-0.885445
0.711979
0.322079
-1.33495
0.122164
-0.557992
0.18845
0.464154
-0.976007
-0.219337
-3.54036
-0.574648
0.0471774
0.45053
-0.182909
-1.30395
0.00889483
-1.24209
-0.244127
0.23063
0.261223
0.391258
-1.06883
0.768058
-0.691217
-0.649089
-0.915342
-0.982764
0.833364
-0.686197
-0.544373
0.124701
0.0931549
0.894742
1.26977
0.465275
1.22823
-0.136561
-0.265499
-0.702372
0.191898
0.4162
-0.0978608
0.422334
-1.52432
0.797237
1.77296
-2.89019
1.87265
-2.47711
12.4715
2.10541
-0.498337
10.5635
-1.5521
-1.30557
-3.30762
2.74033
0.397584
2.70879
-3.68427
1.48244
3.85444
4.4299
-1.54161
0.340718
14.0274
0.535782
3.15473
4.99851
0.31543
-4.4247
-2.16436
-3.27138
0.749815
3.16153
0.749396
3.61953
-1.44855
3.32569
-8.20141
7.56478
7.47719
4.79115
6.78726
-3.97322
-6.79752
7.22035
3.88121
3.33831
10.7813
5.70898
9.69506
-0.667288
2.71161
7.38414
-2.49511
0.402455
-6.50033
-2.46804
9.19452
-11.2624
16.1835
-19.6969
-1.60209
-8.62022
-2.77901
2.99285
-1.19374
4.41262
7.11945
-1.46009
-0.376609
3.64302
3.23597
2.63629
-4.59497
6.7532
-5.843
26.9864
-1.57838
32.6211
1.83577
2.05799
-4.4471
5.95904
2.61936
6.90741
17.2508
-10.6727
-10.5098
13.9673
-4.57747
1.14537
11.7636
-24.1389
-12.7202
-5.20538
-7.43094
-16.7025
-7.92921
-10.7318
-1.10726
-1.33891
3.03124
-0.824739
-3.28492
0.923022
-2.77585
-0.162143
-0.756942
0.718681
-0.416293
2.04037
0.680798
0.180716
0.691242
1.07648
-0.0293622
-0.78316
-0.610536
-0.300859
3.03956
-1.83288
-1.50826
-1.76664
-0.479623
-0.371424
1.32208
-0.142381
-3.3327
1.07086
-1.39264
-2.08937
0.687713
0.524602
-0.049307
0.135355
0.311815
-1.04253
-2.43936
6.66883
-1.44217
9.53616
0.0756811
0.306722
-2.3923
3.63448
-6.43283
6.5969
4.04588
-3.29368
8.40918
-16.2298
-1.95731
-6.52481
6.19746
-0.0305579
-5.68114
-14.9812
11.6868
-0.553382
-13.4087
10.8752
-2.09143
1.44317
2.47094
-6.55578
-7.24457
2.93297
6.55844
-16.8273
-3.8866
-6.22666
-3.01368
-0.539914
0.593275
-0.800839
-1.03658
-0.319689
-0.506699
0.240241
1.16925
0.805213
0.949273
0.196293
-0.880381
0.230656
0.734522
0.113911
0.284499
0.59529
-1.02087
0.145641
-0.504786
-1.66014
-0.854416
-1.0756
0.172001
-0.526144
-0.110098
-0.11341
0.675128
0.719276
0.778709
0.305743
-0.560148
0.0818454
-2.90129
-0.717745
0.382938
-0.752665
3.94366
0.430176
2.3058
3.97921
-2.99352
4.58164
0.811403
2.57067
-2.39851
5.11504
0.437227
2.87126
7.80609
-0.742701
-2.8953
2.34084
-6.05235
0.628606
5.37152
11.5921
-3.76487
3.25848
-2.16761
-2.03735
-0.825588
-1.33118
-0.802364
3.98396
1.63938
1.03647
-0.87665
-22.4809
15.0451
2.11007
-0.162296
9.4651
-0.701699
-1.15005
2.69311
3.83883
-3.6696
-15.1902
-3.51629
1.14656
-7.26774
-13.0475
-14.5534
1.37406
12.7195
12.0695
1.73422
1.63922
-0.775842
9.07354
1.13059
3.60013
5.39337
9.50028
-5.89064
0.0534579
2.13782
1.86385
-10.0812
-10.7862
0.0902834
-6.61979
-7.52614
8.07624
6.69423
16.8012
-13.1319
1.21794
-6.22834
4.00223
7.58925
7.28555
8.291
2.87938
0.582961
-5.57003
14.9738
1.83366
-10.4794
-4.58429
-9.05173
-1.77105
-0.991179
-0.729031
1.23979
8.3539
-7.48559
-3.08569
0.302115
3.92535
1.38167
-1.71278
0.0360892
-7.74554
-3.12954
-2.99376
1.40227
-4.49308
-3.7159
-11.9917
-3.09498
-10.7829
-15.5287
-6.02892
-1.95867
-3.90828
-1.35887
-0.192187
-4.75214
0.355076
3.62628
-1.86362
-4.60379
-7.50841
-8.50488
-3.78083
-0.811231
13.4976
24.8881
19.4938
5.96628
4.4683
0.607856
3.03072
-1.38839
3.29314
-1.97688
0.56783
0.105798
3.20595
4.63635
0.0135468
-7.8624
-7.97457
-3.57702
-3.91393
-1.02771
-7.70094
-0.159837
-2.59098
-3.49077
-2.99151
-0.285463
0.485272
12.5599
-11.9694
-8.23182
-10.4529
-6.59723
-8.41672
-0.232857
21.5648
-3.37609
9.44914
-1.70487
6.29317
3.28059
-0.794515
-2.70375
1.05375
2.24388
0.430348
1.75376
-2.16849
15.5553
-7.09578
1.1834
-0.731635
-0.716065
-8.33663
-15.1767
3.55022
-6.59198
-8.77082
-12.6259
-3.20297
-7.67947
3.30729
-8.58254
0.546298
10.2898
0.269159
2.23525
2.98864
-4.63086
9.25874
27.1822
-5.8942
4.5222
0.881231
-5.10691
-6.95736
0.587162
-0.350785
-5.37603
2.7407

-0.738732
-7.34763
-1.39772
-0.565687
-10.2625
-11.1492
-5.49525
-2.47542
-12.8396
-0.822522
-8.03283
4.071
-4.39337
17.0857
8.26765
5.27663



ann1dn t scr.nn scr void 100  void void 0.5 3


TRAINING SET: 22124


VALIDATION SET: 11344


TEST SET: 11911
ÿ

loading data...
 cls1: 3783  cls2: 41596  files loaded.  size: 33 samples
 validaton size: 945 10399
 validaton size: 993 10918
training...
  epoch: 1   out: 0.641113 0.364608   max acur: 0.54 (epoch 1)   se:73.23 sp:89.73 ac:88.36
  epoch: 2   out: 0.710362 0.293310   max acur: 0.54 (epoch 1)   se:73.23 sp:89.73 ac:88.36
  epoch: 3   out: 0.729230 0.275459   max acur: 0.57 (epoch 3)   se:79.58 sp:89.73 ac:88.88
  epoch: 4   out: 0.740237 0.260448   max acur: 0.58 (epoch 4)   se:81.16 sp:89.56 ac:88.86
  epoch: 5   out: 0.750870 0.248525   max acur: 0.60 (epoch 5)   se:81.16 sp:90.64 ac:89.85
  epoch: 6   out: 0.760660 0.236177   max acur: 0.60 (epoch 5)   se:81.16 sp:90.64 ac:89.85
  epoch: 7   out: 0.767187 0.227271   max acur: 0.63 (epoch 7)   se:83.70 sp:91.56 ac:90.90
  epoch: 8   out: 0.774373 0.217981   max acur: 0.63 (epoch 7)   se:83.70 sp:91.56 ac:90.90
  epoch: 9   out: 0.779923 0.210622   max acur: 0.63 (epoch 9)   se:86.14 sp:90.86 ac:90.47
  epoch: 10   out: 0.784283 0.205488   max acur: 0.63 (epoch 9)   se:86.14 sp:90.86 ac:90.47
  epoch: 11   out: 0.786764 0.200145   max acur: 0.63 (epoch 9)   se:86.14 sp:90.86 ac:90.47
  epoch: 12   out: 0.789045 0.197323   max acur: 0.63 (epoch 9)   se:86.14 sp:90.86 ac:90.47
  epoch: 13   out: 0.791602 0.194255   max acur: 0.63 (epoch 13)   se:89.21 sp:90.02 ac:89.95
  epoch: 14   out: 0.795894 0.190956   max acur: 0.63 (epoch 13)   se:89.21 sp:90.02 ac:89.95
  epoch: 15   out: 0.798398 0.187997   max acur: 0.63 (epoch 13)   se:89.21 sp:90.02 ac:89.95
  epoch: 16   out: 0.799584 0.184943   max acur: 0.67 (epoch 16)   se:83.28 sp:93.72 ac:92.85
  epoch: 17   out: 0.802789 0.183612   max acur: 0.69 (epoch 17)   se:84.34 sp:94.11 ac:93.30
  epoch: 18   out: 0.803667 0.182060   max acur: 0.69 (epoch 17)   se:84.34 sp:94.11 ac:93.30
  epoch: 19   out: 0.807164 0.179207   max acur: 0.69 (epoch 17)   se:84.34 sp:94.11 ac:93.30
  epoch: 20   out: 0.808782 0.177038   max acur: 0.70 (epoch 20)   se:84.55 sp:94.25 ac:93.44
  epoch: 21   out: 0.810718 0.175663   max acur: 0.70 (epoch 20)   se:84.55 sp:94.25 ac:93.44
  epoch: 22   out: 0.814081 0.172692   max acur: 0.70 (epoch 20)   se:84.55 sp:94.25 ac:93.44
  epoch: 23   out: 0.814783 0.172306   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 24   out: 0.816017 0.170113   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 25   out: 0.816376 0.169986   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 26   out: 0.818444 0.168847   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 27   out: 0.818310 0.167504   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 28   out: 0.820986 0.165604   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 29   out: 0.822361 0.163336   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 30   out: 0.824473 0.163249   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 31   out: 0.825045 0.163131   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 32   out: 0.825014 0.161026   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 33   out: 0.828211 0.159582   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 34   out: 0.827581 0.159384   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 35   out: 0.828368 0.159042   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 36   out: 0.830255 0.156850   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 37   out: 0.832107 0.154788   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 38   out: 0.829611 0.156116   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 39   out: 0.833144 0.155220   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 40   out: 0.833663 0.154050   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 41   out: 0.833188 0.154872   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 42   out: 0.835057 0.153665   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 43   out: 0.834598 0.152784   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 44   out: 0.836715 0.150357   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 45   out: 0.837963 0.150134   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 46   out: 0.838357 0.150289   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 47   out: 0.838798 0.149724   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 48   out: 0.840598 0.148339   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 49   out: 0.840161 0.147994   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 50   out: 0.840240 0.148340   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 51   out: 0.840848 0.147604   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 52   out: 0.842338 0.146857   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 53   out: 0.843141 0.145381   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 54   out: 0.843386 0.145553   max acur: 0.71 (epoch 23)   se:78.31 sp:96.12 ac:94.64
  epoch: 55   out: 0.843835 0.145952   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 56   out: 0.843003 0.146138   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 57   out: 0.844425 0.144862   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 58   out: 0.845146 0.145217   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 59   out: 0.845795 0.143234   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 60   out: 0.844463 0.144311   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 61   out: 0.847378 0.142680   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 62   out: 0.847433 0.141371   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 63   out: 0.848530 0.142165   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 64   out: 0.849152 0.141634   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 65   out: 0.848858 0.141581   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 66   out: 0.849559 0.140317   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 67   out: 0.848705 0.141308   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 68   out: 0.850849 0.139150   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 69   out: 0.849319 0.139424   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 70   out: 0.851662 0.138278   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 71   out: 0.852721 0.138129   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 72   out: 0.853015 0.138056   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 73   out: 0.852227 0.137953   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 74   out: 0.854078 0.137335   max acur: 0.75 (epoch 55)   se:86.14 sp:95.90 ac:95.09
  epoch: 75   out: 0.853200 0.136961   max acur: 0.76 (epoch 75)   se:86.67 sp:96.04 ac:95.26
  epoch: 76   out: 0.854368 0.136322   max acur: 0.76 (epoch 75)   se:86.67 sp:96.04 ac:95.26
  epoch: 77   out: 0.853619 0.137140   max acur: 0.76 (epoch 75)   se:86.67 sp:96.04 ac:95.26
  epoch: 78   out: 0.855996 0.135503   max acur: 0.76 (epoch 75)   se:86.67 sp:96.04 ac:95.26
  epoch: 79   out: 0.857237 0.133591   max acur: 0.76 (epoch 75)   se:86.67 sp:96.04 ac:95.26
training done.
training time: 00:06:55:438

classification results: maxacur.nn
 
 train set: 1845 20279
   sensitivity: 89.16
   specificity: 96.55
   +predictive: 70.15
   -predictive: 98.99
      accuracy: 95.93
 
 validation set: 945 10399
   sensitivity: 86.67
   specificity: 96.04
   +predictive: 66.53
   -predictive: 98.75
      accuracy: 95.26
 
 test set: 993 10918
   sensitivity: 87.71
   specificity: 96.84
   +predictive: 71.63
   -predictive: 98.86
      accuracy: 96.08

classification results: scr.nn
 
 train set: 1845 20279
   sensitivity: 96.64
   specificity: 90.86
   +predictive: 49.02
   -predictive: 99.66
      accuracy: 91.34
 
 validation set: 945 10399
   sensitivity: 95.13
   specificity: 89.81
   +predictive: 45.89
   -predictive: 99.51
      accuracy: 90.25
 
 test set: 993 10918
   sensitivity: 95.27
   specificity: 91.52
   +predictive: 50.53
   -predictive: 99.53
      accuracy: 91.83
ÿ



maxacur.nn

